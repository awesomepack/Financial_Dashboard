{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income EDA\n",
    "Exploring Salary data in the United States by using the BLS API\n",
    "[Getting Strated with BLS API](URL 'https://www.bls.gov/developers/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dependencies\n",
    "import json\n",
    "import requests\n",
    "import prettytable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving mapping of survey abbreviations to survey names from BLS\n",
    "headers = {'content-type': 'application/json'}\n",
    "#data = json.dumps({\"seriesid\": ['CUUR0000SA0','SUUR0000SA0'],'latest':'latest'}) # retrieving latest data from a series id\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v2/surveys/')# data=data, headers=headers)\n",
    "json_data = json.loads(p.text)\n",
    "df = pd.DataFrame(json_data['Results']['survey'])\n",
    "\n",
    "# Writing the resulting request to a CSV for manual inspection\n",
    "df.to_csv('Unique_Surveys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The abbreviation for the wage modeling database is WM\n"
     ]
    }
   ],
   "source": [
    "# From the BLS website we know the database we are interseted in is 'Wage Modeling'\n",
    "# We search for its abbreviation by passing the survey name to the dataframe\n",
    "abbreviation = df[df['survey_name'] == 'Wage Modeling'].iloc[0,0]\n",
    "print(f'The abbreviation for the wage modeling database is {abbreviation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect data on the wage estimation from the BLS I need to know the series ID of the data I am looking for. Unfortunately, the BLS does not contain a series ID catalogue and I will have to learn the syntax of series ID's withing the Wage Modeling survey to learn how to access all data.\n",
    "\n",
    "Update: its possible to get a complete dataset of all wage estimates for the different occupations and levels that they handle. The dataset contains the series ID for each estimate they have. We can find the unique ID's and pass them as arguements to the API Call to get the data through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2020 wage estimate dataset and extract unique series ID\n",
    "wageEstimate_DF = pd.read_excel('mwe-2020complete.xlsx', sheet_name=\"MWE 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the columns present in the dataset\n",
    "wageEstimate_DF.columns\n",
    "\n",
    "# Filtering out columns we are not interested in\n",
    "wageEstimate_DF = wageEstimate_DF[['Series title', 'Area text', 'Occupation text',\n",
    "       'Average hourly wage\\n($)',\n",
    "       'Series ID', 'Area code', 'Occupation \\ncode']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the State component from 'Area text' and add as a new column\n",
    "from posixpath import split\n",
    "\n",
    "\n",
    "splitColumns = wageEstimate_DF['Area text'].str.split(pat=',',expand=True)\n",
    "wageEstimate_DF[['Sub-Region', 'State']] = splitColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, ' TX', ' OH', ' GA', ' OR', ' NY', ' NM', ' LA', ' PA-NJ',\n",
       "       ' PA', ' IA', ' AK', ' MI', ' AL', ' WI', ' NC', ' NJ', ' GA-SC',\n",
       "       ' CA', ' MD', ' WV', ' WA', ' MT', ' ND', ' VA', ' IL', ' IN',\n",
       "       ' ID', ' CO', ' KY', ' FL', ' MO-IL', ' NV', ' WY', ' SC',\n",
       "       ' NC-SC', ' TN-GA', ' IL-IN-WI', ' OH-KY-IN', ' TN-KY', ' TN',\n",
       "       ' MO', ' GA-AL', ' MD-WV', ' IA-IL', ' DE', ' MN-WI', ' OK',\n",
       "       ' IN-KY', ' ND-MN', ' AR-MO', ' AZ', ' AR-OK', ' NE', ' MS', ' AR',\n",
       "       ' WV-KY-OH', ' HI', ' MO-KS', ' TN-VA', ' WI-MN', ' KS', ' ID-WA',\n",
       "       ' UT-ID', ' KY-IN', ' MN', ' TN-MS-AR', ' SC-NC', ' NY-NJ-PA',\n",
       "       ' UT', ' NE-IA', ' PA-NJ-DE-MD', ' OR-WA', ' SD', ' MD-DE',\n",
       "       ' IA-NE-SD', ' IN-MI', ' TX-AR', ' VA-NC', ' DC-VA-MD-WV',\n",
       "       ' WV-OH', ' VA-WV', ' OH-PA', ' ME', ' MA', ' MA-NH', ' CT', ' VT',\n",
       "       ' NH-ME', ' NH', ' CT-RI', ' RI-MA', ' MA-CT'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wageEstimate_DF['State'].unique()\n",
    "# 93 unique state instances, there should be roughly 50\n",
    "# Some states are aggregates of up to 3 states\n",
    "# Need to investigate why they are combined, and determine a method of binning them into a single state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ab6cfb7c77f6868107e9499919e4b718bd5f4d06fdb788e771155d72904cd4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
